3:I[4707,[],""]
4:I[6423,[],""]
0:["KOMQv4DAp8gX8zG57soVC",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1","$L2",null],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/c35bd9a771e0cce0.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","className":"__variable_f367f3 __variable_746b61","children":["$","body",null,{"className":"min-h-screen max-w-full bg-navy-50 font-sans text-navy-900 antialiased","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}]}]],null],null],["$L5",null]]]]
5:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Noam Razin"}],["$","meta","3",{"name":"description","content":"Personal academic page of Noam Razin - Postdoctoral Fellow"}],["$","link","4",{"rel":"icon","href":"/icon.png"}],["$","meta","5",{"name":"next-size-adjust"}]]
1:null
6:I[5711,["717","static/chunks/717-433d002070c2287f.js","931","static/chunks/app/page-beeca8ec709bbbf5.js"],"Nav"]
7:I[5878,["717","static/chunks/717-433d002070c2287f.js","931","static/chunks/app/page-beeca8ec709bbbf5.js"],"Image"]
8:I[2972,["717","static/chunks/717-433d002070c2287f.js","931","static/chunks/app/page-beeca8ec709bbbf5.js"],""]
9:I[1426,["717","static/chunks/717-433d002070c2287f.js","931","static/chunks/app/page-beeca8ec709bbbf5.js"],"NewsList"]
a:I[9493,["717","static/chunks/717-433d002070c2287f.js","931","static/chunks/app/page-beeca8ec709bbbf5.js"],"PublicationCard"]
2:["$","main",null,{"id":"top","className":"flex min-h-screen min-w-0 max-w-full flex-col","children":[["$","div",null,{"className":"order-1 sticky top-0 z-30 md:order-2","children":["$","$L6",null,{"showBlog":false}]}],["$","div",null,{"className":"order-2 md:order-1","children":["$","header",null,{"id":"top","className":"min-w-0 border-b border-navy-200/60 bg-navy-900 px-4 pt-10 pb-8 text-white sm:px-6 md:pt-12 md:pb-10","children":["$","div",null,{"className":"mx-auto flex min-w-0 max-w-4xl flex-col items-center gap-6 text-center md:flex-row md:items-center md:gap-8 md:text-left","children":[["$","div",null,{"className":"relative h-48 w-48 shrink-0 overflow-hidden rounded-full border-2 border-navy-600 bg-navy-700 sm:h-52 sm:w-52 md:h-56 md:w-56","children":["$","$L7",null,{"src":"/avatar.jpg","alt":"Noam Razin","fill":true,"className":"object-cover","sizes":"(max-width: 640px) 192px, (max-width: 768px) 208px, 224px","priority":true}]}],["$","div",null,{"className":"flex min-w-0 flex-1 flex-col gap-2 sm:gap-3","children":[["$","h1",null,{"className":"font-serif text-3xl font-bold text-white sm:text-4xl md:text-[2.5rem]","children":"Noam Razin"}],["$","div",null,{"className":"flex flex-col gap-0.5","children":[["$","p",null,{"className":"text-base text-navy-200 sm:text-lg","children":"Postdoctoral Fellow"}],["$","p",null,{"className":"text-base text-navy-200 sm:text-lg","children":"Princeton University"}],["$","span",null,{"className":"text-base text-navy-200 sm:text-lg","children":["Email: ","noamrazin (at) princeton.edu"]}]]}],["$","div",null,{"className":"mt-2 sm:mt-3","children":["$","div",null,{"className":"flex flex-wrap items-center justify-center gap-2 sm:gap-3 md:justify-start","children":[["$","$L8","googleScholar",{"href":"https://scholar.google.com/citations?user=tDsd50oAAAAJ","target":"_blank","rel":"noopener noreferrer","className":"flex h-12 w-12 shrink-0 items-center justify-center rounded-lg bg-navy-700/80 text-navy-200 transition hover:bg-accent hover:text-white sm:h-11 sm:w-11","aria-label":"Google Scholar","style":{"touchAction":"manipulation"},"children":["$","svg",null,{"viewBox":"0 0 24 24","className":"h-5 w-5 sm:h-6 sm:w-6","fill":"currentColor","children":["$","path",null,{"d":"M12 24a7 7 0 1 1 0-14 7 7 0 0 1 0 14zm0-24L0 9.5l4.838 3.94A8 8 0 0 1 12 9a8 8 0 0 1 7.162 4.44L24 9.5z"}]}]}],["$","$L8","twitter",{"href":"https://x.com/noamrazin","target":"_blank","rel":"noopener noreferrer","className":"flex h-12 w-12 shrink-0 items-center justify-center rounded-lg bg-navy-700/80 text-navy-200 transition hover:bg-accent hover:text-white sm:h-11 sm:w-11","aria-label":"Twitter","style":{"touchAction":"manipulation"},"children":["$","svg",null,{"viewBox":"0 0 24 24","className":"h-5 w-5 sm:h-6 sm:w-6","fill":"currentColor","children":["$","path",null,{"d":"M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"}]}]}],["$","$L8","linkedin",{"href":"https://www.linkedin.com/in/noam-razin-4a8969a8/","target":"_blank","rel":"noopener noreferrer","className":"flex h-12 w-12 shrink-0 items-center justify-center rounded-lg bg-navy-700/80 text-navy-200 transition hover:bg-accent hover:text-white sm:h-11 sm:w-11","aria-label":"LinkedIn","style":{"touchAction":"manipulation"},"children":["$","svg",null,{"viewBox":"0 0 24 24","className":"h-5 w-5 sm:h-6 sm:w-6","fill":"currentColor","children":["$","path",null,{"d":"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"}]}]}],["$","$L8","cv",{"href":"/files/nr_cv.pdf","target":"_blank","rel":"noopener noreferrer","className":"flex h-12 shrink-0 items-center justify-center rounded-lg bg-navy-700/80 px-4 text-sm font-semibold text-navy-200 transition hover:bg-accent hover:text-white sm:h-11 sm:px-3.5 sm:text-base","aria-label":"CV (Resume)","style":{"touchAction":"manipulation"},"children":"CV"}]]}]}]]}]]}]}]}],["$","div",null,{"className":"order-3 mx-auto min-w-0 max-w-4xl overflow-x-hidden px-4 py-5 sm:px-6 sm:py-6","children":[["$","section",null,{"id":"about","className":"min-w-0 scroll-mt-20 py-6 md:py-8","children":[null,["$","div",null,{"className":"","children":["$","div",null,{"className":"max-w-none space-y-3 sm:space-y-4 [&_a]:text-accent [&_a]:no-underline [&_a:hover]:underline","children":[false,["$","div",null,{"className":"leading-relaxed text-navy-900 sm:text-lg [&_p+_p]:mt-3 [&_ul]:mt-2 [&_ul]:list-disc [&_ul]:pl-6 [&_li]:my-1","children":[["$","p","p-0",{"children":["I am a Postdoctoral Fellow at ",["$","a",null,{"href":"https://pli.princeton.edu/","target":"_blank","rel":"noopener noreferrer","children":"Princeton Language and Intelligence"}],", Princeton University. My research focuses on the fundamentals of artificial intelligence (AI). By combining mathematical analyses with systematic experimentation, I aim to develop theories that shed light on how modern AI works, identify potential failures, and yield principled methods for improving efficiency, reliability, and performance."]}],"\n",["$","p","p-1",{"children":["My work is supported in part by a ",["$","a",null,{"href":"https://zuckermanstem.org/","target":"_blank","rel":"noopener noreferrer","children":"Zuckerman Postdoctoral Scholarship"}],". Previously, I obtained my PhD in Computer Science at ",["$","a",null,{"href":"https://en-exact-sciences.tau.ac.il/computer","target":"_blank","rel":"noopener noreferrer","children":"Tel Aviv University"}],", where I was fortunate to be advised by ",["$","a",null,{"href":"http://www.cohennadav.com/","target":"_blank","rel":"noopener noreferrer","children":"Nadav Cohen"}],". During my PhD, I interned at ",["$","a",null,{"href":"https://machinelearning.apple.com/","target":"_blank","rel":"noopener noreferrer","children":"Apple Machine Learning Research"}]," and Microsoft Recommendations Team, and received the ",["$","a",null,{"href":"https://machinelearning.apple.com/updates/apple-scholars-aiml-2022","target":"_blank","rel":"noopener noreferrer","children":"Apple Scholars in AI/ML"}]," and ",["$","a",null,{"href":"https://datascience.tau.ac.il/","target":"_blank","rel":"noopener noreferrer","children":"Tel Aviv University Center for AI & Data Science"}]," fellowships."]}]]}],["$","div",null,{"className":"space-y-3","children":[["$","div","0",{"className":"flex items-center gap-2 rounded-lg bg-accent-muted/30 shadow-sm ring-1 ring-navy-200/60 py-2.5 pl-4 pr-5 text-navy-800 sm:text-lg font-medium dark:bg-accent/15 dark:ring-navy-600/50","children":[["$","span",null,{"className":"flex h-10 w-10 shrink-0 items-center justify-center text-accent","aria-hidden":true,"children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":"2.5","strokeLinecap":"round","strokeLinejoin":"round","className":"h-5 w-5","children":[["$","circle",null,{"cx":"12","cy":"12","r":"10"}],["$","path",null,{"d":"M12 16v-4"}],["$","path",null,{"d":"M12 8h.01"}]]}]}],["$","div",null,{"className":"min-w-0 flex-1 [&_a]:text-accent [&_a]:no-underline [&_a:hover]:underline","children":["$","p","p-0",{"children":"I am on the academic and industry job market for 2025/26"}]}]]}]]}]]}]}]]}],["$","section",null,{"id":"research","className":"min-w-0 scroll-mt-20 py-6 md:py-8","children":[["$","h2",null,{"className":"mb-4 flex items-center gap-3 font-serif text-3xl font-semibold text-navy-900 sm:text-3xl md:text-4xl","children":[["$","span",null,{"className":"text-navy-600","children":["$","svg",null,{"viewBox":"0 0 24 24","className":"h-7 w-7 shrink-0 sm:h-7 sm:w-7","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","circle",null,{"cx":"11","cy":"11","r":"8"}],["$","path",null,{"d":"m21 21-4.35-4.35"}]]}]}],"Recent Research"]}],["$","div",null,{"className":"$undefined","children":["$","div",null,{"className":"max-w-none [&_a]:text-accent [&_a]:no-underline [&_a:hover]:underline","children":["$","div",null,{"className":"leading-relaxed text-navy-900 sm:text-lg [&_p+_p]:mt-3 [&_ul]:mt-2 [&_ul]:list-disc [&_ul]:pl-6 [&_li]:my-1","children":[["$","p","p-0",{"children":"Recently, I have been working on language model alignment, including reinforcement learning and preference optimization approaches."}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":["In ",["$","a",null,{"href":"https://arxiv.org/abs/2310.20703","target":"_blank","rel":"noopener noreferrer","children":"[1]"}],", we identify a connection between reward variance and the flatness of the reinforcement learning objective landscape. Building on this, ",["$","a",null,{"href":"https://arxiv.org/abs/2503.15477","target":"_blank","rel":"noopener noreferrer","children":"[2]"}]," provides an optimization perspective on what makes a good reward model for RLHF, establishing that more accurate reward models are not necessarily better."]}],"\n",["$","li","li-1",{"children":["In ",["$","a",null,{"href":"https://arxiv.org/abs/2507.07981","target":"_blank","rel":"noopener noreferrer","children":"[3]"}],", we investigate why language models are often poor implicit reward models, and show that they tend to rely on superficial token-level cues."]}],"\n",["$","li","li-2",{"children":["In ",["$","a",null,{"href":"https://arxiv.org/abs/2410.08847","target":"_blank","rel":"noopener noreferrer","children":"[4]"}],", we characterize the causes of ",["$","em","em-0",{"children":"likelihood displacement"}]," — the counter-intuitive phenomenon where preference optimization decreases the probability of preferred responses (instead of increasing it as intended). We demonstrate that likelihood displacement can cause surprising failures in alignment and give preventative guidelines."]}],"\n"]}]]}]}]}]]}],["$","section",null,{"id":"news","className":"min-w-0 scroll-mt-20 py-6 md:py-8","children":[["$","h2",null,{"className":"mb-4 flex items-center gap-3 font-serif text-3xl font-semibold text-navy-900 sm:text-3xl md:text-4xl","children":[["$","span",null,{"className":"text-navy-600","children":["$","svg",null,{"viewBox":"0 0 24 24","className":"h-7 w-7 shrink-0 sm:h-7 sm:w-7","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","path",null,{"d":"M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2"}],["$","path",null,{"d":"M18 14h-8"}],["$","path",null,{"d":"M15 18h-5"}],["$","path",null,{"d":"M10 6h8v4h-8V6Z"}]]}]}],"News"]}],["$","div",null,{"className":"$undefined","children":["$","$L9",null,{}]}]]}],["$","section",null,{"id":"publications","className":"min-w-0 scroll-mt-20 py-6 md:py-8","children":[["$","h2",null,{"className":"mb-4 flex items-center gap-3 font-serif text-3xl font-semibold text-navy-900 sm:text-3xl md:text-4xl","children":[["$","span",null,{"className":"text-navy-600","children":["$","svg",null,{"viewBox":"0 0 24 24","className":"h-7 w-7 shrink-0 sm:h-7 sm:w-7","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","path",null,{"d":"M4 19.5A2.5 2.5 0 0 1 6.5 17H20"}],["$","path",null,{"d":"M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"}],["$","path",null,{"d":"M8 7h8"}],["$","path",null,{"d":"M8 11h8"}]]}]}],"Publications"]}],["$","div",null,{"className":"$undefined","children":["$","div",null,{"className":"space-y-3 sm:space-y-4","children":[["$","p",null,{"className":"text-sm text-navy-600","children":"* denotes equal contribution"}],[["$","$La","0",{"pub":{"title":"Why is Your Language Model a Poor Implicit Reward Model?","image":"/paper_avatars/why_is_your_lm_poor_rm_avatar.png","authors":"Noam Razin, Yong Lin, Jiarui Yao, Sanjeev Arora","venue":"International Conference on Learning Representations (ICLR)","year":2026,"bibtex":"bibtex/razin2026why.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2507.07981"},{"type":"code","label":"Code","url":"https://github.com/princeton-pli/exrm-vs-imrm"},{"type":"poster","label":"Poster","url":"files/posters/why_is_your_lm_poor_rm_poster.pdf"}],"tags":[],"bibtexContent":"@inproceedings{razin2026why,\n  title={Why is Your Language Model a Poor Implicit Reward Model?},\n  author={Razin, Noam and Lin, Yong and Yao, Jiarui and Arora, Sanjeev},\n  booktitle={International Conference on Learning Representations},\n  year={2026}\n}"},"showImage":true}],["$","$La","1",{"pub":{"title":"Retaining by Doing: The Role of On-Policy Data in Mitigating Forgetting","image":"/paper_avatars/sft_vs_rl_forgetting.png","authors":"Howard Chen, Noam Razin, Karthik Narasimhan, Danqi Chen","venue":"arXiv:2510.18874","year":2025,"bibtex":"bibtex/chen2025retaining.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2510.18874"},{"type":"code","label":"Code","url":"https://github.com/princeton-pli/retaining-by-doing"}],"tags":[],"bibtexContent":"@article{chen2025retaining,\n  title={Retaining by Doing: The Role of On-Policy Data in Mitigating Forgetting},\n  author={Chen, Howard and Razin, Noam and Narasimhan, Karthik and Chen, Danqi},\n  journal={arXiv preprint arXiv:2510.18874},\n  year={2025}\n}"},"showImage":true}],["$","$La","2",{"pub":{"title":"What Makes a Reward Model a Good Teacher? An Optimization Perspective","image":"/paper_avatars/what_makes_good_rm_avatar.png","authors":"Noam Razin, Zixuan Wang, Hubert Strauss, Stanley Wei, Jason D. Lee, Sanjeev Arora","venue":"Advances in Neural Information Processing Systems (NeurIPS)","year":2025,"bibtex":"bibtex/razin2025what.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2503.15477"},{"type":"code","label":"Code","url":"https://github.com/princeton-pli/what-makes-good-rm"},{"type":"poster","label":"Poster","url":"files/posters/what_makes_good_rm_poster.pdf"}],"tags":[],"bibtexContent":"@inproceedings{razin2025what,\n  title={What Makes a Reward Model a Good Teacher? An Optimization Perspective},\n  author={Razin, Noam and Wang, Zixuan and Strauss, Hubert and Wei, Stanley and Lee, Jason D and Arora, Sanjeev},\n  booktitle={Advances in Neural Information Processing Systems},\n  year={2025}\n}"},"showImage":true}],["$","$La","3",{"pub":{"title":"Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization","image":"/paper_avatars/likelihood_displacement.png","authors":"Noam Razin, Sadhika Malladi, Adithya Bhaskar, Danqi Chen, Sanjeev Arora, Boris Hanin","venue":"International Conference on Learning Representations (ICLR)","year":2025,"bibtex":"bibtex/razin2025unintentional.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2410.08847"},{"type":"code","label":"Code","url":"https://github.com/princeton-nlp/unintentional-unalignment"},{"type":"poster","label":"Poster","url":"files/posters/likelihood_displacement_poster.pdf"}],"tags":[],"bibtexContent":"@inproceedings{razin2025unintentional,\n  title={Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization},\n  author={Razin, Noam and Malladi, Sadhika and Bhaskar, Adithya and Chen, Danqi and Arora, Sanjeev and Hanin, Boris},\n  booktitle={International Conference on Learning Representations},\n  year={2025}\n}\n"},"showImage":true}],["$","$La","4",{"pub":{"title":"The Implicit Bias of Structured State Space Models Can Be Poisoned With Clean Labels","image":"/paper_avatars/imp_bias_ssm.png","authors":"Yonatan Slutzky*, Yotam Alexander*, Noam Razin, Nadav Cohen","venue":"Advances in Neural Information Processing Systems (NeurIPS)","year":2025,"bibtex":"bibtex/slutzky2025implicit.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2410.10473"},{"type":"code","label":"Code","url":"https://github.com/YoniSlutzky98/imp-bias-ssm-poison"}],"tags":[],"bibtexContent":"@inproceedings{slutzky2025implicit,\n  title={The Implicit Bias of Structured State Space Models Can Be Poisoned With Clean Labels},\n  author={Slutzky, Yonatan and Alexander, Yotam and Razin, Noam and Cohen, Nadav},\n  booktitle={Advances in Neural Information Processing Systems},\n  year={2025}\n}"},"showImage":true}],["$","$La","5",{"pub":{"title":"Understanding Deep Learning via Notions of Rank","image":"/paper_avatars/phd_thesis.png","authors":"Noam Razin","venue":"arXiv:2408.02111 (PhD thesis)","year":2024,"bibtex":"bibtex/razin2024understanding.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2408.02111"}],"tags":[],"bibtexContent":"@phdthesis{razin2024understanding,\n  title={Understanding Deep Learning via Notions of Rank},\n  author={Razin, Noam},\n  journal={arXiv preprint arXiv:2408.02111},\n  year={2024}\n}"},"showImage":true}],["$","$La","6",{"pub":{"title":"Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States","image":"/paper_avatars/imp_bias_lqr.png","authors":"Noam Razin*, Yotam Alexander*, Edo Cohen-Karlik, Raja Giryes, Amir Globerson, Nadav Cohen","venue":"International Conference on Machine Learning (ICML)","year":2024,"bibtex":"bibtex/razin2024implicit.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2402.07875"},{"type":"code","label":"Code","url":"https://github.com/noamrazin/imp_bias_control"},{"type":"poster","label":"Poster","url":"files/posters/implicit_bias_in_lqr_poster.pdf"}],"tags":[],"bibtexContent":"@inproceedings{razin2024implicit,\n  title={Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States},\n  author={Razin, Noam and Alexander, Yotam and Cohen-Karlik, Edo and Giryes, Raja and Globerson, Amir and Cohen, Nadav},\n  booktitle={International Conference on Machine Learning},\n  year={2024}\n}"},"showImage":true}],["$","$La","7",{"pub":{"title":"Vanishing Gradients in Reinforcement Finetuning of Language Models","image":"/paper_avatars/vanish_grad_rft.png","authors":"Noam Razin, Hattie Zhou, Omid Saremi, Vimal Thilak, Arwen Bradley, Preetum Nakkiran, Joshua Susskind, Etai Littwin","venue":"International Conference on Learning Representations (ICLR)","year":2024,"bibtex":"bibtex/razin2024vanishing.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2310.20703"},{"type":"code","label":"Code","url":"https://github.com/apple/ml-rlgrad"},{"type":"poster","label":"Poster","url":"files/posters/vanishing_grad_rft_iclr_2024_poster.pdf"}],"tags":[],"bibtexContent":"@inproceedings{razin2024vanishing,\n  title={Vanishing Gradients in Reinforcement Finetuning of Language Models},\n  author={Razin, Noam and Zhou, Hattie and Saremi, Omid and Thilak, Vimal and Bradley, Arwen and Nakkiran, Preetum and Susskind, Joshua and Littwin, Etai},\n  booktitle={International Conference on Learning Representations},\n  year={2024}\n}"},"showImage":true}],["$","$La","8",{"pub":{"title":"What Algorithms Can Transformers Learn? A Study in Length Generalization","image":"/paper_avatars/what_algs_transformers_learn.png","authors":"Hattie Zhou, Arwen Bradley, Etai Littwin, Noam Razin, Omid Saremi, Joshua Susskind, Samy Bengio, Preetum Nakkiran","venue":"International Conference on Learning Representations (ICLR)","year":2024,"bibtex":"bibtex/zhou2024what.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2310.16028"},{"type":"code","label":"Code","url":"https://github.com/apple/ml-np-rasp"}],"tags":[],"bibtexContent":"@inproceedings{zhou2024what,\n  title={What Algorithms Can Transformers Learn? A Study in Length Generalization},\n  author={Zhou, Hattie and Bradley, Arwen and Littwin, Etai and Razin, Noam and Saremi, Omid and Susskind, Joshua and Bengio, Samy and Nakkiran, Preetum},\n  booktitle={International Conference on Learning Representations},\n  year={2024}\n}"},"showImage":true}],["$","$La","9",{"pub":{"title":"Lecture Notes on Linear Neural Networks: A Tale of Optimization and Generalization in Deep Learning","image":"/paper_avatars/lnn_lecture_notes.png","authors":"Nadav Cohen, Noam Razin","venue":"arXiv:2408.13767","year":2024,"bibtex":"bibtex/cohen2024lecture.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2408.13767"}],"tags":[],"bibtexContent":"@article{cohen2024lecture,\n  title={Lecture Notes on Linear Neural Networks: A Tale of Optimization and Generalization in Deep Learning},\n  author={Cohen, Nadav and Razin, Noam},\n  journal={arXiv preprint arXiv:2408.13767},\n  year={2024}\n}"},"showImage":true}],["$","$La","10",{"pub":{"title":"What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement","image":"/paper_avatars/data_qe.png","authors":"Yotam Alexander*, Nimrod De La Vega*, Noam Razin, Nadav Cohen","venue":"Advances in Neural Information Processing Systems (NeurIPS)","year":2023,"bibtex":"bibtex/alexander2023what.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2303.11249"},{"type":"code","label":"Code","url":"https://github.com/nmd95/data_suitable_lc_nn_code"}],"tags":[],"bibtexContent":"@inproceedings{alexander2023what,\n  title={What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement},\n  author={Alexander, Yotam and De La Vega, Nimrod and Razin, Noam and Cohen, Nadav},\n  booktitle={Advances in Neural Information Processing Systems},\n  year={2023}\n}"},"showImage":true}],["$","$La","11",{"pub":{"title":"On the Ability of Graph Neural Networks to Model Interactions Between Vertices","image":"/paper_avatars/gnn_interactions.png","authors":"Noam Razin, Tom Verbin, Nadav Cohen","venue":"Advances in Neural Information Processing Systems (NeurIPS)","year":2023,"bibtex":"bibtex/razin2023ability.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2211.16494"},{"type":"code","label":"Code","url":"https://github.com/noamrazin/gnn_interactions"},{"type":"poster","label":"Poster","url":"files/posters/gnn_interactions_poster.pdf"}],"tags":[],"bibtexContent":"@inproceedings{razin2023ability,\n  title={On the Ability of Graph Neural Networks to Model Interactions Between Vertices},\n  author={Razin, Noam and Verbin, Tom and Cohen, Nadav},\n  booktitle={Advances in Neural Information Processing Systems},\n  year={2023}\n}"},"showImage":true}],["$","$La","12",{"pub":{"title":"Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks","image":"/paper_avatars/imp_reg_htf.png","authors":"Noam Razin, Asaf Maman, Nadav Cohen","venue":"International Conference on Machine Learning (ICML)","year":2022,"bibtex":"bibtex/razin2022implicit.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2201.11729"},{"type":"blog","label":"Blog","url":"https://www.offconvex.org/2022/07/15/imp-reg-htf-cnn/"},{"type":"code","label":"Code","url":"https://github.com/asafmaman101/imp_reg_htf"}],"tags":[],"bibtexContent":"@inproceedings{razin2022implicit,\n  title={Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks},\n  author={Razin, Noam and Maman, Asaf and Cohen, Nadav},\n  booktitle={International Conference on Machine Learning},\n  year={2022}\n}"},"showImage":true}],["$","$La","13",{"pub":{"title":"Implicit Regularization in Tensor Factorization","image":"/paper_avatars/imp_reg_tf.png","authors":"Noam Razin*, Asaf Maman*, Nadav Cohen","venue":"International Conference on Machine Learning (ICML)","year":2021,"bibtex":"bibtex/razin2021implicit.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2102.09972"},{"type":"blog","label":"Blog","url":"https://www.offconvex.org/2021/07/08/imp-reg-tf/"},{"type":"code","label":"Code","url":"https://github.com/noamrazin/imp_reg_in_tf"}],"tags":[],"bibtexContent":"@inproceedings{razin2021implicit,\n  title={Implicit Regularization in Tensor Factorization},\n  author={Razin, Noam and Maman, Asaf and Cohen, Nadav},\n  booktitle={International Conference on Machine Learning},\n  year={2021}\n}"},"showImage":true}],["$","$La","14",{"pub":{"title":"Implicit Regularization in Deep Learning May Not Be Explainable by Norms","image":"/paper_avatars/reg_dl_not_norms.png","authors":"Noam Razin, Nadav Cohen","venue":"Advances in Neural Information Processing Systems (NeurIPS)","year":2020,"bibtex":"bibtex/razin2020implicit.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2005.06398"},{"type":"blog","label":"Blog","url":"https://www.offconvex.org/2020/11/27/reg_dl_not_norm/"},{"type":"code","label":"Code","url":"https://github.com/noamrazin/imp_reg_dl_not_norms"}],"tags":[],"bibtexContent":"@inproceedings{razin2020implicit,\n  title={Implicit Regularization in Deep Learning May Not Be Explainable by Norms},\n  author={Razin, Noam and Cohen, Nadav},\n  booktitle={Advances in Neural Information Processing Systems},\n  year={2020}\n}"},"showImage":true}],["$","$La","15",{"pub":{"title":"RecoBERT: A Catalog Language Model for Text-Based Recommendations","image":"/paper_avatars/recobert.png","authors":"Itzik Malkiel, Oren Barkan, Avi Caciularu, Noam Razin, Ori Katz, Noam Koenigstein","venue":"Findings of the Association for Computational Linguistics: EMNLP","year":2020,"bibtex":"bibtex/malkiel2020recobert.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/2009.13292"}],"tags":[],"bibtexContent":"@inproceedings{malkiel2020recobert,\n  title={RecoBERT: A Catalog Language Model for Text-Based Recommendations},\n  author={Malkiel, Itzik and Barkan, Oren and Caciularu, Avi and Razin, Noam and Katz, Ori and Koenigstein, Noam},\n  booktitle={Findings of the Association for Computational Linguistics: EMNLP},\n  year={2020}\n}"},"showImage":true}],["$","$La","16",{"pub":{"title":"Scalable Attentive Sentence-Pair Modeling via Distilled Sentence Embedding","image":"/paper_avatars/dse.jpg","authors":"Oren Barkan*, Noam Razin*, Itzik Malkiel, Ori Katz, Avi Caciularu, Noam Koenigstein","venue":"AAAI Conference on Artificial Intelligence (AAAI)","year":2020,"bibtex":"bibtex/barkan2020scalable.bib","links":[{"type":"pdf","label":"PDF","url":"https://arxiv.org/pdf/1908.05161"},{"type":"code","label":"Code","url":"https://github.com/microsoft/Distilled-Sentence-Embedding"}],"tags":[],"bibtexContent":"@inproceedings{barkan2020scalable,\n  title={Scalable Attentive Sentence-Pair Modeling via Distilled Sentence Embedding},\n  author={Barkan, Oren and Razin, Noam and Malkiel, Itzik and Katz, Ori and Caciularu, Avi and Koenigstein, Noam},\n  booktitle={AAAI Conference on Artificial Intelligence},\n  year={2020}\n}"},"showImage":true}]]]}]}]]}],["$","section",null,{"id":"talks","className":"min-w-0 scroll-mt-20 py-6 md:py-8","children":[["$","h2",null,{"className":"mb-4 flex items-center gap-3 font-serif text-3xl font-semibold text-navy-900 sm:text-3xl md:text-4xl","children":[["$","span",null,{"className":"text-navy-600","children":["$","svg",null,{"viewBox":"0 0 24 24","className":"h-7 w-7 shrink-0 sm:h-7 sm:w-7","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","path",null,{"d":"M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"}],["$","path",null,{"d":"M19 10v2a7 7 0 0 1-14 0v-2"}],["$","line",null,{"x1":"12","y1":"19","x2":"12","y2":"22"}],["$","line",null,{"x1":"8","y1":"22","x2":"16","y2":"22"}]]}]}],"Selected Talks"]}],["$","div",null,{"className":"$undefined","children":["$","ul",null,{"className":"space-y-3 sm:space-y-4","children":[["$","li","0",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-accent bg-white p-4 shadow-sm sm:p-5","children":["$","div",null,{"className":"flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-start sm:justify-between sm:gap-4","children":[["$","div",null,{"className":"min-w-0 flex-1","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Understanding and Overcoming Pitfalls in Language Model Alignment"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["EPFL AI Fundamentals Seminar",""," · ","Sep 2025"]}]]}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","$L8",null,{"href":"files/slides/understanding_and_overcoming_pitfalls_in_lm_alignment.pdf","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","rect",null,{"x":"2","y":"5","width":"14","height":"10","rx":"1"}],["$","rect",null,{"x":"6","y":"9","width":"14","height":"10","rx":"1"}],["$","path",null,{"d":"M6 9V7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v2"}]]}],"Slides"]}],["$","$L8",null,{"href":"https://www.youtube.com/watch?v=1lK7_waEmkg","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":["$","polygon",null,{"points":"5 3 19 12 5 21 5 3"}]}],"Video"]}]]}]]}]}],["$","li","1",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-accent bg-white p-4 shadow-sm sm:p-5","children":["$","div",null,{"className":"flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-start sm:justify-between sm:gap-4","children":[["$","div",null,{"className":"min-w-0 flex-1","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["Deep Learning: Classics and Trends Seminar",""," · ","Jan 2025"]}]]}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","$L8",null,{"href":"files/slides/likelihood_displacement.pdf","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","rect",null,{"x":"2","y":"5","width":"14","height":"10","rx":"1"}],["$","rect",null,{"x":"6","y":"9","width":"14","height":"10","rx":"1"}],["$","path",null,{"d":"M6 9V7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v2"}]]}],"Slides"]}],""]}]]}]}],["$","li","2",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-accent bg-white p-4 shadow-sm sm:p-5","children":["$","div",null,{"className":"flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-start sm:justify-between sm:gap-4","children":[["$","div",null,{"className":"min-w-0 flex-1","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Analyses of Policy Gradient for Language Model Finetuning and Optimal Control"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["MPI MiS + UCLA Math Machine Learning Seminar",""," · ","Mar 2024"]}]]}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","$L8",null,{"href":"files/slides/policy_grad_lm_control_mml.pdf","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","rect",null,{"x":"2","y":"5","width":"14","height":"10","rx":"1"}],["$","rect",null,{"x":"6","y":"9","width":"14","height":"10","rx":"1"}],["$","path",null,{"d":"M6 9V7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v2"}]]}],"Slides"]}],["$","$L8",null,{"href":"https://www.mis.mpg.de/events/event/analyses-of-policy-gradient-for-language-model-finetuning-and-optimal-control","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":["$","polygon",null,{"points":"5 3 19 12 5 21 5 3"}]}],"Video"]}]]}]]}]}],["$","li","3",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-accent bg-white p-4 shadow-sm sm:p-5","children":["$","div",null,{"className":"flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-start sm:justify-between sm:gap-4","children":[["$","div",null,{"className":"min-w-0 flex-1","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Two Analyses of Modern Deep Learning: Graph Neural Networks and Language Model Finetuning"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["Princeton Alg-ML Seminar",""," · ","Dec 2023"]}]]}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","$L8",null,{"href":"files/slides/modern_dl_gnns_lm_finetuning.pdf","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","rect",null,{"x":"2","y":"5","width":"14","height":"10","rx":"1"}],["$","rect",null,{"x":"6","y":"9","width":"14","height":"10","rx":"1"}],["$","path",null,{"d":"M6 9V7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v2"}]]}],"Slides"]}],""]}]]}]}],["$","li","4",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-accent bg-white p-4 shadow-sm sm:p-5","children":["$","div",null,{"className":"flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-start sm:justify-between sm:gap-4","children":[["$","div",null,{"className":"min-w-0 flex-1","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"On the Ability of Graph Neural Networks to Model Interactions Between Vertices"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["Learning on Graphs and Geometry Reading Group",""," · ","Jan 2023"]}]]}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","$L8",null,{"href":"files/slides/gnn_interactions_talk_log2.pdf","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","rect",null,{"x":"2","y":"5","width":"14","height":"10","rx":"1"}],["$","rect",null,{"x":"6","y":"9","width":"14","height":"10","rx":"1"}],["$","path",null,{"d":"M6 9V7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v2"}]]}],"Slides"]}],["$","$L8",null,{"href":"https://www.youtube.com/watch?v=eMLelK5Qa4E","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":["$","polygon",null,{"points":"5 3 19 12 5 21 5 3"}]}],"Video"]}]]}]]}]}],["$","li","5",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-accent bg-white p-4 shadow-sm sm:p-5","children":["$","div",null,{"className":"flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-start sm:justify-between sm:gap-4","children":[["$","div",null,{"className":"min-w-0 flex-1","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Generalization in Deep Learning Through the Lens of Implicit Rank Lowering"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["ICTP Youth in High-Dimensions: Recent Progress in Machine Learning, High-Dimensional Statistics and Inference",""," · ","Jun 2022"]}]]}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","$L8",null,{"href":"files/slides/gen_in_dl_via_imp_rank_low_ictp_slides.pdf","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","rect",null,{"x":"2","y":"5","width":"14","height":"10","rx":"1"}],["$","rect",null,{"x":"6","y":"9","width":"14","height":"10","rx":"1"}],["$","path",null,{"d":"M6 9V7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v2"}]]}],"Slides"]}],["$","$L8",null,{"href":"https://www.youtube.com/watch?v=2vPBvad_q28","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":["$","polygon",null,{"points":"5 3 19 12 5 21 5 3"}]}],"Video"]}]]}]]}]}],["$","li","6",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-accent bg-white p-4 shadow-sm sm:p-5","children":["$","div",null,{"className":"flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-start sm:justify-between sm:gap-4","children":[["$","div",null,{"className":"min-w-0 flex-1","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Implicit Regularization in Tensor Factorization"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["The Hebrew University Machine Learning Club",""," · ","Jun 2021"]}]]}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","$L8",null,{"href":"files/slides/imp_reg_tf_talk_slides.pdf","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","rect",null,{"x":"2","y":"5","width":"14","height":"10","rx":"1"}],["$","rect",null,{"x":"6","y":"9","width":"14","height":"10","rx":"1"}],["$","path",null,{"d":"M6 9V7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v2"}]]}],"Slides"]}],["$","$L8",null,{"href":"https://www.youtube.com/watch?v=koyqZk58YuA","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":["$","polygon",null,{"points":"5 3 19 12 5 21 5 3"}]}],"Video"]}]]}]]}]}],["$","li","7",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-accent bg-white p-4 shadow-sm sm:p-5","children":["$","div",null,{"className":"flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-start sm:justify-between sm:gap-4","children":[["$","div",null,{"className":"min-w-0 flex-1","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Implicit Regularization in Deep Learning May Not Be Explainable by Norms"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["Tel Aviv University Machine Learning Seminar",""," · ","May 2020"]}]]}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","$L8",null,{"href":"files/slides/imp_reg_dl_not_norms_slides.pdf","target":"_blank","rel":"noopener noreferrer","className":"inline-flex min-h-[32px] min-w-[32px] items-center justify-center gap-1 rounded-lg border border-navy-200/80 bg-navy-100 px-2 py-1 text-xs font-medium text-navy-800 transition hover:bg-navy-200 sm:min-h-0 sm:min-w-0 sm:px-2.5 sm:py-1.5","style":{"touchAction":"manipulation"},"children":[["$","svg",null,{"viewBox":"0 0 24 24","className":"h-3.5 w-3.5 shrink-0","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","rect",null,{"x":"2","y":"5","width":"14","height":"10","rx":"1"}],["$","rect",null,{"x":"6","y":"9","width":"14","height":"10","rx":"1"}],["$","path",null,{"d":"M6 9V7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v2"}]]}],"Slides"]}],""]}]]}]}]]}]}]]}],["$","section",null,{"id":"teaching","className":"min-w-0 scroll-mt-20 py-6 md:py-8","children":[["$","h2",null,{"className":"mb-4 flex items-center gap-3 font-serif text-3xl font-semibold text-navy-900 sm:text-3xl md:text-4xl","children":[["$","span",null,{"className":"text-navy-600","children":["$","svg",null,{"viewBox":"0 0 24 24","className":"h-7 w-7 shrink-0 sm:h-7 sm:w-7","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","children":[["$","path",null,{"d":"M22 10v6M2 10l10-5 10 5-10 5z"}],["$","path",null,{"d":"M6 12v5c3 3 9 3 12 0v-5"}]]}]}],"Teaching"]}],["$","div",null,{"className":"$undefined","children":["$","ul",null,{"className":"space-y-3 sm:space-y-4","children":[["$","li","0",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-teal-500 bg-white p-4 shadow-sm sm:p-5","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Fundamentals of Deep Learning (COS 514)"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["Guest Lecturer"," · ","Princeton University"," · ","2025"]}],"$undefined"]}],["$","li","1",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-teal-500 bg-white p-4 shadow-sm sm:p-5","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Introduction to Reinforcement Learning (COS 435)"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["Guest Lecturer"," · ","Princeton University"," · ","2025"]}],"$undefined"]}],["$","li","2",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-teal-500 bg-white p-4 shadow-sm sm:p-5","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"First Steps in Research Honors Seminar"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["Guest Lecturer"," · ","Tel Aviv University"," · ","2021–2024"]}],"$undefined"]}],["$","li","3",{"className":"rounded-xl border border-navy-200/80 border-l-4 border-l-teal-500 bg-white p-4 shadow-sm sm:p-5","children":[["$","p",null,{"className":"font-serif text-lg font-medium text-navy-900 sm:text-xl","style":{"lineHeight":1.15,"textWrap":"pretty"},"children":"Foundations of Deep Learning"}],["$","p",null,{"className":"mt-1 text-sm text-navy-600 sm:text-base","children":["Teaching Assistant"," · ","Tel Aviv University"," · ","2021–2023"]}],"$undefined"]}]]}]}]]}],false]}],["$","footer",null,{"className":"order-4 flex min-w-0 items-center justify-center gap-5 border-t border-navy-200 bg-navy-900/5 px-4 py-2.5 text-sm text-navy-600 sm:py-3","children":[["$","div",null,{"className":"flex flex-col items-center gap-0.5","children":[["$","span",null,{"children":"© 2026 Noam Razin"}],["$","span",null,{"className":"text-xs text-navy-500","children":["Last updated: ","February 5th, 2026"]}]]}],["$","a",null,{"href":"#top","aria-label":"Back to top","className":"inline-flex h-9 w-9 shrink-0 items-center justify-center rounded-full border border-navy-200/80 bg-white text-navy-600 shadow-sm transition-all hover:bg-navy-50 hover:text-navy-900 hover:shadow focus:outline-none focus:ring-2 focus:ring-navy-300 focus:ring-offset-1","children":["$","svg",null,{"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":"2","strokeLinecap":"round","strokeLinejoin":"round","className":"h-4 w-4 shrink-0","aria-hidden":true,"children":["$","path",null,{"d":"M12 19V5M5 12l7-7 7 7"}]}]}]]}]]}]
